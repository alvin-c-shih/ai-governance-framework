---
sequence: 22
title: Regulatory Compliance and Oversight
layout: risk
doc-status: Pre-Draft
type: RC
external_risks:
  - NIST-600_2024_2-09  # NIST 600.1: Information Security
ffiec_references:
  - ffiec_mgt_i-governance
  - ffiec_mgt_ii-risk-management
  - ffiec_aud_internal-audit-program
  - ffiec_aud_risk-assessment-and-risk-based-auditing
eu-ai_references:
  - eu-ai_c3-s2-a8  # III.S2.A8 Compliance with the Requirements
  - eu-ai_c3-s3-a21  # III.S3.A21 Cooperation with Competent Authorities
  - eu-ai_c3-s3-a16  # III.S3.A16 Obligations of Providers of High-Risk AI Systems
---

- Financial services are heavily regulated, and AI use does not exempt firms from compliance.  
- Regulators affirm that AI-generated content must follow the same rules as human decisions.  
- AI tools providing financial advice must comply with suitability requirements and avoid misleading statements.  
- AI-generated marketing or customer communications must be fair, accurate, and non-exaggerated.  
- Record-keeping laws (e.g., MiFID II, SEC rules) may require firms to retain AI-generated outputs.  
- Banking regulators mandate sound AI risk management, validation, and governance.  
- AI models informing credit, capital, or trading decisions must undergo model governance review.  
- Firms risk non-compliance if they fail to supervise AI systems adequately.  
- Evolving regulations (e.g., EU AI Act) may impose stricter oversight on AI in high-risk areas like credit scoring.  
- Non-compliance with AI regulations can lead to fines, restrictions, or litigation.

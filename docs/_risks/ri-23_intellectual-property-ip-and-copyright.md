---
sequence: 23
title: Intellectual Property (IP) and Copyright
layout: risk
doc-status: Draft
type: RC
nist-ai-600-1_references:
  - 2-10  # 2.10. Intellectual Property
ffiec-itbooklets_references:
  - mgt-1  # MGT: I   Governance
  - mgt-2  # MGT: II Risk Management
  - ots-2  # OTS: Risk Management
  - dam-6  # DAM: VI Acquisition
eu-ai-act_references:
  - c3-s2-a10  # III.S2.A10: Data and Data Governance
  - c3-s2-a11  # III.S2.A11: Technical Documentation
  - c5-s2-a53  # V.S2.A53: Obligations for Providers of General-Purpose AI Models
---

## Summary

Generative AI models may be trained on copyrighted or proprietary material, raising the risk that outputs could unintentionally infringe on intellectual property rights. In financial services, this could lead to legal liability if AI-generated content includes copyrighted text, code, or reveals sensitive business information. Additional risks arise when employees input confidential data into public AI tools, potentially leaking trade secrets or violating licensing terms.

## Description

Generative AI models are often trained on vast and diverse datasets, which may contain copyrighted material, proprietary code, or protected intellectual property. When these models are used in financial services—whether to generate documents, code, communications, or analytical reports—there is a risk that outputs may unintentionally replicate or closely resemble copyrighted content, exposing the firm to potential legal claims of infringement.

This can lead to several IP-related challenges for financial institutions:

* **Copyright Infringement through AI-Generated Content**: AI models may generate outputs that are substantially similar to, or derivative of, copyrighted works present in their training data. Financial institutions could face legal liability for copyright infringement if they use or distribute such AI-generated content. This could manifest if AI-generated marketing copy closely resembles a competitor's copyrighted materials, if code produced by an AI assistant for internal financial modelling tools replicates snippets from licensed or proprietary software, or if AI-generated research reports inadvertently include passages from copyrighted financial analyses.

* **Loss of Proprietary Information and Trade Secrets**: A significant risk involves the potential leakage of a financial institution's own valuable IP when employees interact with AI models, particularly public or third-party hosted tools. Inputting confidential information—such as proprietary trading algorithms, sensitive client data analyses, M&A strategies, unreleased financial product details, or internal operational know-how—into these AI systems can lead to the irretrievable loss of trade secrets. There have been instances where firms have accidentally leaked sensitive internal code or confidential business strategies through the use of AI tools.

* **Licensing and Usage Rights for AI Models and Platforms**: Financial institutions must ensure that the AI models, platforms, and APIs they utilize are properly licensed for commercial purposes. The terms of service for AI tools can vary widely, and failure to adhere to licensing conditions could result in contractual breaches or loss of access to critical AI capabilities.

### Consequences

The consequences of inadequately managing these IP and copyright risks can be severe for financial institutions:

* **Legal Action and Financial Penalties**: This includes copyright infringement lawsuits, claims of trade secret misappropriation, and potential court-ordered injunctions, leading to substantial legal costs, damages, and fines.
* **Loss of Competitive Advantage**: The inadvertent disclosure of proprietary algorithms, unique business processes, or confidential strategic information can significantly erode an institution's competitive edge.
* **Reputational Damage**: Being publicly associated with IP infringement or the careless handling of confidential business information can severely damage an institution's brand and stakeholder trust.
* **Contractual Breaches**: Misappropriating third-party IP or leaking client-confidential information through AI systems can lead to breaches of contracts with clients, partners, or software vendors.

Effectively mitigating these risks requires financial institutions to implement robust IP governance frameworks, conduct thorough due diligence on AI vendors and their data handling practices, provide clear policies and training to employees on the acceptable use of AI tools (especially concerning proprietary data), and potentially utilize AI systems that offer strong data protection and IP safeguards.



---
sequence: 20
title: Reputational Risk
layout: risk
doc-status: Pre-Draft
type: OP
external_risks:
  - OWASP-LLM_2025_LLM09  # OWASP LLM: Misinformation
ffiec_references:
  - ffiec_mgt_ii-risk-management
  - ffiec_bcm_iii-risk-management
  - ffiec_aud_risk-assessment-and-risk-based-auditing
eu-ai_references:
  - eu-ai_c2-a5  # II.A5 Prohibited AI Practices
  - eu-ai_c3-s2-a9  # III.S2.A9 Risk Management System
  - eu-ai_c3-s2-a14  # III.S2.A14 Human Oversight
---

- AI failures or misuse can quickly become public incidents, eroding trust.  
- Customer-facing GenAI (e.g., chatbots) can generate offensive, inaccurate, or unfair content.  
- Bad press and reputational damage can result from AI-driven unfair treatment or errors.  
- Compliance failures linked to AI can lead to regulatory fines and scrutiny.  
- The financial sector relies on trust—AI mistakes can severely impact a firm’s reputation.  
- High-profile errors, such as biased loan denials or flawed investor reports, can be damaging.  
- Regulators have flagged AI-related reputational risk as a key concern.  
- Firms must recognize that AI-driven services reflect on their overall conduct.  
- AI can scale errors rapidly, potentially sending flawed messages to thousands of customers.  
- Reputation damage from AI mistakes is a significant operational risk.


---
sequence: 18
title: Model Overreach and Misuse
layout: risk
doc-status: Pre-Draft
type: OP
external_risks:
  - OWASP-LLM_2025_LLM06  # OWASP LLM: Excessive Agency
ffiec_references:
  - ffiec_mgt_i-governance
  - ffiec_mgt_ii-risk-management
  - ffiec_aud_risk-assessment-and-risk-based-auditing
eu-ai_references:
  - eu-ai_c3-s1-a6  # III.S1.A6 Classification Rules for High-Risk AI Systems
  - eu-ai_c3-s2-a14  # III.S2.A14 Human Oversight
  - eu-ai_c3-s3-a26  # III.S3.A26 Obligations of Deployers of High-Risk AI Systems
---

- The impressive capabilities of GenAI can lead to overestimation of its abilities.  
- Staff may be tempted to use AI beyond its intended scope.  
- AI trained for one task (e.g., marketing emails) might be misused for another (e.g., investment advice or legal documents).  
- Misuse of AI can result in poor-quality or non-compliant outcomes.  
- Overreliance on AI without understanding its limitations can cause operational mistakes.  
- Compliance breaches may occur if AI is used inappropriately.  
- Anthropomorphism—treating AI as a human expert—can increase the risk of misplaced trust.  
- Users may accept AI-generated recommendations too readily, leading to potential errors.


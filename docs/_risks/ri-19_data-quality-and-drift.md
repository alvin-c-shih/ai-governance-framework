---
sequence: 19
title: Data Quality and Drift
layout: risk
doc-status: Pre-Draft
type: OP
external_risks:
- NIST-600_2024_2-08    # Information Integrity
---

- Generative AIâ€™s outputs depend on the quality and recency of its training data.  
- Poor-quality or outdated data can lead to unreliable or irrelevant results.  
- AI models can become stale if not regularly retrained.  
- Lack of updated training may cause AI to miss market shifts or regulatory changes.  
- In fast-moving financial markets, stale models can lead to flawed risk assessments and compliance failures.  
- Errors or biases in training data can be reflected and even amplified in AI outputs.  
- Maintaining data integrity is a continuous operational challenge.

